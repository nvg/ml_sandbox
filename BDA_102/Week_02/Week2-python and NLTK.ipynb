{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text prepration in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('Canada_wiki.txt', encoding=\"UTF-8\")\n",
    "raw_data=f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Canada (/ˈkænədə/ (About this sound listen); French: [kanadɑ]) is a country in the northern part of North America. Its ten provinces and three territories extend from the Atlantic to the Pacific and northward into the Arctic Ocean, covering 9.98 million square kilometres (3.85 million square miles),'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=raw_data.replace(\"(/ˈkænədə/ (About this sound listen); French: [kanadɑ])\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Canada  is a country in the northern part of North America. Its ten provinces and three territories extend from the Atlantic to the Pacific and northward into the Arctic Ocean, covering 9.98 million square kilometres (3.85 million square miles), making it the world's second-largest country by total \""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Text Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "#Alternatives for word tokenizer\n",
    "#from nltk.tokenize import TreebankWordTokenizer\n",
    "#from nltk.tokenize import WordPunctTokenizer\n",
    "#from nltk.tokenize import regexp_tokenize\n",
    "#regexp_tokenize(data,[\\w']+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sent_List=sent_tokenize(data) # create list of the sentenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canada  is a country in the northern part of North America.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Sent_List[0])\n",
    "len(Sent_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_List=word_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Canada', 'is', 'a', 'country', 'in', 'the', 'northern', 'part', 'of', 'North', 'America', '.', 'Its', 'ten', 'provinces', 'and', 'three', 'territories', 'extend', 'from', 'the', 'Atlantic', 'to', 'the', 'Pacific', 'and', 'northward', 'into', 'the', 'Arctic', 'Ocean', ',', 'covering', '9.98', 'million', 'square', 'kilometres', '(', '3.85', 'million', 'square', 'miles', ')', ',', 'making', 'it', 'the', 'world', \"'s\", 'second-largest', 'country', 'by', 'total', 'area', 'and', 'the', 'fourth-largest', 'country', 'by', 'land', 'area', '.', 'Canada', \"'s\", 'southern', 'border', 'with', 'the', 'United', 'States', 'is', 'the', 'world', \"'s\", 'longest', 'bi-national', 'land', 'border', '.', 'The', 'majority', 'of', 'the', 'country', 'has', 'a', 'cold', 'or', 'severely', 'cold', 'winter', 'climate', ',', 'but', 'southerly', 'areas', 'are', 'warm', 'in', 'summer']\n"
     ]
    }
   ],
   "source": [
    "len(world_List)\n",
    "print(world_List[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data visuaization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sent_len=[]\n",
    "for i in Sent_List:\n",
    "    Sent_len.append(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 0., 0., 0., 0., 1., 0., 0., 1., 3., 2., 0., 0., 4., 2., 3., 1.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " array([ 57.  ,  63.44,  69.88,  76.32,  82.76,  89.2 ,  95.64, 102.08,\n",
       "        108.52, 114.96, 121.4 , 127.84, 134.28, 140.72, 147.16, 153.6 ,\n",
       "        160.04, 166.48, 172.92, 179.36, 185.8 , 192.24, 198.68, 205.12,\n",
       "        211.56, 218.  , 224.44, 230.88, 237.32, 243.76, 250.2 , 256.64,\n",
       "        263.08, 269.52, 275.96, 282.4 , 288.84, 295.28, 301.72, 308.16,\n",
       "        314.6 , 321.04, 327.48, 333.92, 340.36, 346.8 , 353.24, 359.68,\n",
       "        366.12, 372.56, 379.  ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Sent_len, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stop_words=set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'me', 'ourselves', 'just', \"that'll\", 'mightn', 'shouldn', 'haven', \"didn't\", \"won't\", 'your', 'mustn', \"needn't\", 'until', 'were', \"hadn't\", 'after', 'was', 'no', 'while', 'itself', 'this', 'them', \"you'll\", 'below', 'ain', \"should've\", \"hasn't\", \"weren't\", 'at', 'by', 'in', 'does', 'm', 'where', 'how', 'nor', 'hasn', 'are', \"mightn't\", 'hadn', \"mustn't\", 'for', \"shouldn't\", 'an', 'more', 'a', 'can', 'her', 't', 'now', 'against', 'very', 'do', 'through', 'there', 'he', 'themselves', 'same', 'further', 'his', 'she', 'herself', 'it', 'have', 'other', 'had', 'hers', 'down', 'y', 'the', 'has', 'with', 'each', \"she's\", 'over', 'few', 'we', 'ma', \"couldn't\", 'been', \"isn't\", 'should', 'on', 'off', 'i', 'once', 'yourself', 'wouldn', 'doesn', 'any', 'not', 'doing', 'you', 'him', \"you'd\", 'to', 'our', 'am', 'will', 'out', \"don't\", 'couldn', \"wasn't\", 'they', 'most', \"aren't\", 'didn', 'but', 'why', 'before', 'again', 's', \"doesn't\", 'between', 'don', 'ours', 'own', 'from', 'whom', 'weren', 'both', 'yourselves', 'only', 'as', 'here', 'these', 'll', 're', 'won', 'o', 'what', 'of', 'into', 'needn', 'that', 'or', 'having', \"you've\", 'd', \"you're\", 'too', \"it's\", 'aren', 'who', 'so', 'my', 've', 'up', \"haven't\", 'theirs', 'its', 'above', 'those', 'yours', 'all', 'if', 'isn', \"shan't\", 'being', 'then', 'and', 'some', 'myself', 'such', 'wasn', 'during', 'which', 'about', 'than', \"wouldn't\", 'be', 'is', 'did', 'when', 'shan', 'himself', 'under', 'because', 'their'}\n"
     ]
    }
   ],
   "source": [
    "print(Stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_word=[w for w in world_List if not w in Stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major difference between the porter and lancaster stemming algorithms is that the lancaster stemmer is significantly more aggressive than the porter stemmer. \n",
    "\n",
    "* Porter: porter is a rule based stemmer. Most commonly used stemmer with one of the most gentle stemmers. \n",
    "* Porter2 Stemmer: It is very similar to \"Porter Stemmer\" but with slightly improved rules. \n",
    "* Lancaster: Very aggressive stemming algorithm, sometimes to a fault."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "#from stemming.porter2 import stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS=PorterStemmer()\n",
    "LS=LancasterStemmer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stem_words=[PS.stem(w) for w in filtered_word]\n",
    "Stem_words2=[LS.stem(w) for w in filtered_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country',\n",
       " 'northern',\n",
       " 'part',\n",
       " 'North',\n",
       " 'America',\n",
       " '.',\n",
       " 'Its',\n",
       " 'ten',\n",
       " 'provinces']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_word[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['countri',\n",
       " 'northern',\n",
       " 'part',\n",
       " 'north',\n",
       " 'america',\n",
       " '.',\n",
       " 'it',\n",
       " 'ten',\n",
       " 'provinc']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stem_words[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country', 'northern', 'part', 'nor', 'americ', '.', 'it', 'ten', 'provint']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stem_words2[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "rs=RegexpStemmer('ing')\n",
    "Stem_words3=[rs.stem(w) for w in filtered_word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "tagged=nltk.pos_tag(filtered_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Canada', 'NNP'),\n",
       " ('country', 'NN'),\n",
       " ('northern', 'JJ'),\n",
       " ('part', 'NN'),\n",
       " ('North', 'NNP'),\n",
       " ('America', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Its', 'PRP$'),\n",
       " ('ten', 'JJ'),\n",
       " ('provinces', 'NNS')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking\n",
    "\n",
    "An Ngram, also called an N-gram, is a statistical analysis of text or speech content to find n (a number) of some sort of item in the text. The search item can be all sorts of things, including phonemes, prefixes, phrases, and letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.chunk import RegexpParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Verbose\n"
     ]
    }
   ],
   "source": [
    "%xmode verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the grammar rule\n",
    "# adverb+verb+Proper noun+noun/? can be exist or not/* zero or more\n",
    "n_gram=r\"n_gram:{<RB>*<NN>*<NNP>+<NN>*}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_parser=RegexpParser(n_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chunk=n_gram_parser.parse(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(n_gram Canada/NNP country/NN)\n",
      "('northern', 'JJ')\n",
      "(n_gram part/NN North/NNP America/NNP)\n",
      "('.', '.')\n",
      "('Its', 'PRP$')\n",
      "('ten', 'JJ')\n",
      "('provinces', 'NNS')\n",
      "('three', 'CD')\n",
      "('territories', 'NNS')\n",
      "('extend', 'VBP')\n",
      "(n_gram Atlantic/NNP Pacific/NNP)\n",
      "(n_gram northward/RB Arctic/NNP Ocean/NNP)\n",
      "(',', ',')\n",
      "('covering', 'VBG')\n",
      "('9.98', 'CD')\n",
      "('million', 'CD')\n",
      "('square', 'JJ')\n",
      "('kilometres', 'NNS')\n",
      "('(', '(')\n",
      "('3.85', 'CD')\n",
      "('million', 'CD')\n",
      "('square', 'JJ')\n",
      "('miles', 'NNS')\n",
      "(')', ')')\n",
      "(',', ',')\n",
      "('making', 'VBG')\n",
      "('world', 'NN')\n",
      "(\"'s\", 'POS')\n",
      "('second-largest', 'JJ')\n",
      "('country', 'NN')\n",
      "('total', 'JJ')\n",
      "('area', 'NN')\n",
      "('fourth-largest', 'JJ')\n",
      "('country', 'NN')\n",
      "('land', 'NN')\n",
      "('area', 'NN')\n",
      "('.', '.')\n",
      "(n_gram Canada/NNP)\n",
      "(\"'s\", 'POS')\n",
      "('southern', 'JJ')\n",
      "(n_gram border/NN United/NNP)\n",
      "('States', 'NNPS')\n",
      "('world', 'NN')\n",
      "(\"'s\", 'POS')\n",
      "('longest', 'JJS')\n",
      "('bi-national', 'JJ')\n",
      "('land', 'NN')\n",
      "('border', 'NN')\n",
      "('.', '.')\n",
      "('The', 'DT')\n",
      "('majority', 'NN')\n",
      "('country', 'NN')\n",
      "('cold', 'VBD')\n",
      "('severely', 'RB')\n",
      "('cold', 'JJ')\n",
      "('winter', 'NN')\n",
      "('climate', 'NN')\n",
      "(',', ',')\n",
      "('southerly', 'RB')\n",
      "('areas', 'NNS')\n",
      "('warm', 'VBP')\n",
      "('summer', 'NN')\n",
      "('.', '.')\n",
      "(n_gram Canada/NNP)\n",
      "('sparsely', 'RB')\n",
      "('populated', 'VBD')\n",
      "(',', ',')\n",
      "('majority', 'NN')\n",
      "('land', 'NN')\n",
      "('territory', 'NN')\n",
      "('dominated', 'VBN')\n",
      "('forest', 'JJS')\n",
      "(n_gram tundra/NN Rocky/NNP Mountains/NNP)\n",
      "('.', '.')\n",
      "('It', 'PRP')\n",
      "('highly', 'RB')\n",
      "('urbanized', 'VBD')\n",
      "('82', 'CD')\n",
      "('per', 'IN')\n",
      "('cent', 'NN')\n",
      "('35.15', 'CD')\n",
      "('million', 'CD')\n",
      "('people', 'NNS')\n",
      "('concentrated', 'JJ')\n",
      "('large', 'JJ')\n",
      "('medium-sized', 'JJ')\n",
      "('cities', 'NNS')\n",
      "(',', ',')\n",
      "('many', 'JJ')\n",
      "('near', 'IN')\n",
      "('southern', 'JJ')\n",
      "('border', 'NN')\n",
      "('.', '.')\n",
      "('Its', 'PRP$')\n",
      "(n_gram capital/NN Ottawa/NNP)\n",
      "(',', ',')\n",
      "('five', 'CD')\n",
      "('largest', 'JJS')\n",
      "('metropolitan', 'NN')\n",
      "('areas', 'NNS')\n"
     ]
    }
   ],
   "source": [
    "#n_chunk.draw()\n",
    "for i in range(0,100,1):\n",
    "    print(n_chunk[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi Gram\n",
    "\n",
    "A bigram makes a prediction for a word based on the one before, and a trigram makes a prediction for the word based on the two words before that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.collocations import *\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.metrics import TrigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 'Canada'),\n",
       " ('areas', 'are'),\n",
       " ('world', \"'s\"),\n",
       " ('million', 'square'),\n",
       " ('southern', 'border'),\n",
       " ('ten', 'provinces'),\n",
       " ('three', 'territories'),\n",
       " ('Canada', 'is'),\n",
       " ('North', 'America'),\n",
       " ('United', 'States')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of the words to be printed\n",
    "n=10\n",
    "finder=BigramCollocationFinder.from_words(world_List)\n",
    "finder.nbest(BigramAssocMeasures.likelihood_ratio,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 'Canada', 'is'),\n",
       " ('Canada', 'is', 'a'),\n",
       " ('.', 'It', 'is'),\n",
       " ('the', 'world', \"'s\"),\n",
       " ('.', 'Canada', 'achieved'),\n",
       " ('provinces', 'and', 'three'),\n",
       " ('ten', 'provinces', 'and'),\n",
       " ('the', 'United', 'States'),\n",
       " ('.', 'Canada', \"'s\"),\n",
       " ('areas', 'are', 'Toronto')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder=TrigramCollocationFinder.from_words(world_List)\n",
    "finder.nbest(TrigramAssocMeasures.likelihood_ratio,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Nick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjective:pos=\"a\"\n",
    "# Adverb:pos=\"r\"\n",
    "# Noun:pos=\"n\"\n",
    "# Verb:pos=\"v\"\n",
    "wnl.lemmatize(\"better\",pos=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/nltk_data/\n",
    "         Chunker,\n",
    "         Corpora,\n",
    "         Grammer,\n",
    "         Sentiment,\n",
    "         Stemmer,\n",
    "         Tagger,\n",
    "         Tokenizer,\n",
    "\n",
    "nltk_data/Corpora/\n",
    "          Wordnet,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------similarity-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1=\"win\"\n",
    "word2=\"award\"\n",
    "word3=\"cat\"\n",
    "synarray1=wordnet.synsets(word1)\n",
    "synarray2=wordnet.synsets(word2)\n",
    "synarray3=wordnet.synsets(word3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('win.n.01'),\n",
       " Synset('winnings.n.01'),\n",
       " Synset('win.v.01'),\n",
       " Synset('acquire.v.05'),\n",
       " Synset('gain.v.05'),\n",
       " Synset('succeed.v.01')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synarray1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('award.n.01'),\n",
       " Synset('award.n.02'),\n",
       " Synset('prize.n.01'),\n",
       " Synset('award.v.01'),\n",
       " Synset('award.v.02')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synarray2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('cat.n.01'),\n",
       " Synset('guy.n.01'),\n",
       " Synset('cat.n.03'),\n",
       " Synset('kat.n.01'),\n",
       " Synset('cat-o'-nine-tails.n.01'),\n",
       " Synset('caterpillar.n.02'),\n",
       " Synset('big_cat.n.01'),\n",
       " Synset('computerized_tomography.n.01'),\n",
       " Synset('cat.v.01'),\n",
       " Synset('vomit.v.01')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synarray3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=synarray1[3]\n",
    "w2=synarray2[3]\n",
    "w3=synarray3[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"win something through one's efforts\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.definition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypernym: More abstract, it goes one category above the current level of defenition, \n",
    "\n",
    "Hyponym: More detailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('cozen.v.03')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('get.v.01')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('acquire.v.05.acquire'),\n",
       " Lemma('acquire.v.05.win'),\n",
       " Lemma('acquire.v.05.gain')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'win'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.lemmas()[1].name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Wu - Palmer Similarity\n",
    "# how to words are similar\n",
    "w1.wup_similarity(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many path exist between\n",
    "w1.path_similarity(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.258096538021482"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# leacok chodorow\n",
    "w1.lch_similarity(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.wup_similarity(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.wup_similarity(w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1111111111111111"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.path_similarity(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0608719606852628"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.lch_similarity(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref=w1.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('get.v.01')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.shortest_path_distance(ref[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----Regular Expression-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex=re.compile(r'don\\'t')\n",
    "txt=\"I don't go to school\"\n",
    "sst=regex.sub(\"do not\",txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I do not go to school'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex=re.compile(r'\\w{3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'123g_***'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex.sub(r'123','biig_***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WikiData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='https://www.wikidata.org/w/api.php'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='J. K. Rowling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "param={'action':'wbsearchentities','format':'json','search':query,'language':'en'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=requests.get(path,params=param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'searchinfo': {'search': 'J. K. Rowling'},\n",
       " 'search': [{'repository': 'local',\n",
       "   'id': 'Q34660',\n",
       "   'concepturi': 'http://www.wikidata.org/entity/Q34660',\n",
       "   'title': 'Q34660',\n",
       "   'pageid': 37368,\n",
       "   'url': '//www.wikidata.org/wiki/Q34660',\n",
       "   'label': 'J. K. Rowling',\n",
       "   'description': 'English novelist',\n",
       "   'match': {'type': 'label', 'language': 'en', 'text': 'J. K. Rowling'}},\n",
       "  {'repository': 'local',\n",
       "   'id': 'Q5410773',\n",
       "   'concepturi': 'http://www.wikidata.org/entity/Q5410773',\n",
       "   'title': 'Q5410773',\n",
       "   'pageid': 5175022,\n",
       "   'url': '//www.wikidata.org/wiki/Q5410773',\n",
       "   'label': 'Harry Potter universe',\n",
       "   'description': 'fictional universe created by J. K. Rowling',\n",
       "   'match': {'type': 'alias',\n",
       "    'language': 'en',\n",
       "    'text': \"J. K. Rowling's Wizarding World\"},\n",
       "   'aliases': [\"J. K. Rowling's Wizarding World\"]},\n",
       "  {'repository': 'local',\n",
       "   'id': 'Q57918468',\n",
       "   'concepturi': 'http://www.wikidata.org/entity/Q57918468',\n",
       "   'title': 'Q57918468',\n",
       "   'pageid': 57833012,\n",
       "   'url': '//www.wikidata.org/wiki/Q57918468',\n",
       "   'label': 'J. K. Rowling: Harry Potter',\n",
       "   'description': 'article',\n",
       "   'match': {'type': 'label',\n",
       "    'language': 'en',\n",
       "    'text': 'J. K. Rowling: Harry Potter'}},\n",
       "  {'repository': 'local',\n",
       "   'id': 'Q43361',\n",
       "   'concepturi': 'http://www.wikidata.org/entity/Q43361',\n",
       "   'title': 'Q43361',\n",
       "   'pageid': 45569,\n",
       "   'url': '//www.wikidata.org/wiki/Q43361',\n",
       "   'label': \"Harry Potter and the Philosopher's Stone\",\n",
       "   'description': 'fantasy novel by J. K. Rowling',\n",
       "   'match': {'type': 'alias',\n",
       "    'language': 'sv',\n",
       "    'text': 'J. K. Rowling: Harry Potter och de vises sten'},\n",
       "   'aliases': ['J. K. Rowling: Harry Potter och de vises sten']},\n",
       "  {'repository': 'local',\n",
       "   'id': 'Q46751',\n",
       "   'concepturi': 'http://www.wikidata.org/entity/Q46751',\n",
       "   'title': 'Q46751',\n",
       "   'pageid': 48889,\n",
       "   'url': '//www.wikidata.org/wiki/Q46751',\n",
       "   'label': 'Harry Potter and the Goblet of Fire',\n",
       "   'description': 'fantasy novel by J. K. Rowling',\n",
       "   'match': {'type': 'alias',\n",
       "    'language': 'sv',\n",
       "    'text': 'J. K. Rowling: Harry Potter och Den Flammande Bägaren'},\n",
       "   'aliases': ['J. K. Rowling: Harry Potter och Den Flammande Bägaren']},\n",
       "  {'repository': 'local',\n",
       "   'id': 'Q80817',\n",
       "   'concepturi': 'http://www.wikidata.org/entity/Q80817',\n",
       "   'title': 'Q80817',\n",
       "   'pageid': 83297,\n",
       "   'url': '//www.wikidata.org/wiki/Q80817',\n",
       "   'label': 'Harry Potter and the Order of the Phoenix',\n",
       "   'description': 'fantasy novel by J. K. Rowling',\n",
       "   'match': {'type': 'alias',\n",
       "    'language': 'sv',\n",
       "    'text': 'J. K. Rowling: Harry Potter och Fenixorden'},\n",
       "   'aliases': ['J. K. Rowling: Harry Potter och Fenixorden']},\n",
       "  {'repository': 'local',\n",
       "   'id': 'Q17895706',\n",
       "   'concepturi': 'http://www.wikidata.org/entity/Q17895706',\n",
       "   'title': 'Q17895706',\n",
       "   'pageid': 19463867,\n",
       "   'url': '//www.wikidata.org/wiki/Q17895706',\n",
       "   'label': 'J. K. Rowling pode escrever oitavo livro de Harry Potter',\n",
       "   'description': 'Wikinews article',\n",
       "   'match': {'type': 'label',\n",
       "    'language': 'pt',\n",
       "    'text': 'J. K. Rowling pode escrever oitavo livro de Harry Potter'}}],\n",
       " 'search-continue': 7,\n",
       " 'success': 1}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English novelist'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()['search'][0]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wikidata-sparql query service\n",
    "# https://query.wikidata.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Johann Sebastian Bach.\n",
    "#SELECT ?item ?itemLabel \n",
    "#WHERE\n",
    "#{\n",
    "#  ?item educated at University of Edinburgh.\n",
    "#}\n",
    "\n",
    "#Wikidata, items and properties are not identified by human-readable names like “father” (property) or “Bach” (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The SPARQL service makes use of two key namespaces: \n",
    "#wd: , which is where items live\n",
    "#wdt: for elements that serve as a simplified representation of properties, directly connecting items and values. \n",
    "#The 't' in wdt: stands for \"truthy\".\n",
    "\n",
    "#SELECT ?item ?itemLabel \n",
    "#WHERE \n",
    "#{\n",
    "#  ?item wdt:P69 wd:Q160302\n",
    "#  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "#}\n",
    "#you can find the code by enterring #control+space"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
