{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks with Python and SciKit Learn!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "Neural Networks are a machine learning framework that attempts to mimic the learning pattern of natural biological neural networks. \n",
    "To create a neural network, we simply begin to add layers of perceptrons together, creating a multi-layer perceptron model of a neural network. You'll have an input layer which directly takes in your feature inputs and an output layer which will create the resulting outputs. Any layers in between are known as hidden layers because they don't directly \"see\" the feature inputs or outputs.\n",
    "\n",
    "https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wine = pd.read_csv('wine_data.csv', names = [\"Cultivator\", \"Alchol\", \"Malic_Acid\", \"Ash\", \"Alcalinity_of_Ash\", \"Magnesium\", \"Total_phenols\", \"Falvanoids\", \"Nonflavanoid_phenols\", \"Proanthocyanins\", \"Color_intensity\", \"Hue\", \"OD280\", \"Proline\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cultivator</th>\n",
       "      <th>Alchol</th>\n",
       "      <th>Malic_Acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_Ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Falvanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cultivator  Alchol  Malic_Acid   Ash  Alcalinity_of_Ash  Magnesium  \\\n",
       "0           1   14.23        1.71  2.43               15.6        127   \n",
       "1           1   13.20        1.78  2.14               11.2        100   \n",
       "2           1   13.16        2.36  2.67               18.6        101   \n",
       "3           1   14.37        1.95  2.50               16.8        113   \n",
       "4           1   13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total_phenols  Falvanoids  Nonflavanoid_phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color_intensity   Hue  OD280  Proline  \n",
       "0             5.64  1.04   3.92     1065  \n",
       "1             4.38  1.05   3.40     1050  \n",
       "2             5.68  1.03   3.17     1185  \n",
       "3             7.80  0.86   3.45     1480  \n",
       "4             4.32  1.04   2.93      735  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cultivator</th>\n",
       "      <td>178.0</td>\n",
       "      <td>1.938202</td>\n",
       "      <td>0.775035</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alchol</th>\n",
       "      <td>178.0</td>\n",
       "      <td>13.000618</td>\n",
       "      <td>0.811827</td>\n",
       "      <td>11.03</td>\n",
       "      <td>12.3625</td>\n",
       "      <td>13.050</td>\n",
       "      <td>13.6775</td>\n",
       "      <td>14.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malic_Acid</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.6025</td>\n",
       "      <td>1.865</td>\n",
       "      <td>3.0825</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ash</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>1.36</td>\n",
       "      <td>2.2100</td>\n",
       "      <td>2.360</td>\n",
       "      <td>2.5575</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcalinity_of_Ash</th>\n",
       "      <td>178.0</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>10.60</td>\n",
       "      <td>17.2000</td>\n",
       "      <td>19.500</td>\n",
       "      <td>21.5000</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magnesium</th>\n",
       "      <td>178.0</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>70.00</td>\n",
       "      <td>88.0000</td>\n",
       "      <td>98.000</td>\n",
       "      <td>107.0000</td>\n",
       "      <td>162.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_phenols</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.7425</td>\n",
       "      <td>2.355</td>\n",
       "      <td>2.8000</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Falvanoids</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.2050</td>\n",
       "      <td>2.135</td>\n",
       "      <td>2.8750</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <td>178.0</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <td>178.0</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>1.555</td>\n",
       "      <td>1.9500</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color_intensity</th>\n",
       "      <td>178.0</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>1.28</td>\n",
       "      <td>3.2200</td>\n",
       "      <td>4.690</td>\n",
       "      <td>6.2000</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hue</th>\n",
       "      <td>178.0</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.7825</td>\n",
       "      <td>0.965</td>\n",
       "      <td>1.1200</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OD280</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.9375</td>\n",
       "      <td>2.780</td>\n",
       "      <td>3.1700</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proline</th>\n",
       "      <td>178.0</td>\n",
       "      <td>746.893258</td>\n",
       "      <td>314.907474</td>\n",
       "      <td>278.00</td>\n",
       "      <td>500.5000</td>\n",
       "      <td>673.500</td>\n",
       "      <td>985.0000</td>\n",
       "      <td>1680.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count        mean         std     min       25%  \\\n",
       "Cultivator            178.0    1.938202    0.775035    1.00    1.0000   \n",
       "Alchol                178.0   13.000618    0.811827   11.03   12.3625   \n",
       "Malic_Acid            178.0    2.336348    1.117146    0.74    1.6025   \n",
       "Ash                   178.0    2.366517    0.274344    1.36    2.2100   \n",
       "Alcalinity_of_Ash     178.0   19.494944    3.339564   10.60   17.2000   \n",
       "Magnesium             178.0   99.741573   14.282484   70.00   88.0000   \n",
       "Total_phenols         178.0    2.295112    0.625851    0.98    1.7425   \n",
       "Falvanoids            178.0    2.029270    0.998859    0.34    1.2050   \n",
       "Nonflavanoid_phenols  178.0    0.361854    0.124453    0.13    0.2700   \n",
       "Proanthocyanins       178.0    1.590899    0.572359    0.41    1.2500   \n",
       "Color_intensity       178.0    5.058090    2.318286    1.28    3.2200   \n",
       "Hue                   178.0    0.957449    0.228572    0.48    0.7825   \n",
       "OD280                 178.0    2.611685    0.709990    1.27    1.9375   \n",
       "Proline               178.0  746.893258  314.907474  278.00  500.5000   \n",
       "\n",
       "                          50%       75%      max  \n",
       "Cultivator              2.000    3.0000     3.00  \n",
       "Alchol                 13.050   13.6775    14.83  \n",
       "Malic_Acid              1.865    3.0825     5.80  \n",
       "Ash                     2.360    2.5575     3.23  \n",
       "Alcalinity_of_Ash      19.500   21.5000    30.00  \n",
       "Magnesium              98.000  107.0000   162.00  \n",
       "Total_phenols           2.355    2.8000     3.88  \n",
       "Falvanoids              2.135    2.8750     5.08  \n",
       "Nonflavanoid_phenols    0.340    0.4375     0.66  \n",
       "Proanthocyanins         1.555    1.9500     3.58  \n",
       "Color_intensity         4.690    6.2000    13.00  \n",
       "Hue                     0.965    1.1200     1.71  \n",
       "OD280                   2.780    3.1700     4.00  \n",
       "Proline               673.500  985.0000  1680.00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 178 data points with 13 features and 1 label column\n",
    "wine.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up our Data and our Labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = wine.drop('Cultivator',axis=1)\n",
    "y = wine['Cultivator']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "\n",
    "Let's split our data into training and testing sets, this is done easily with SciKit Learn's train_test_split function from model_selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "The neural network may have difficulty converging before the maximum number of iterations allowed if the data is not normalized. Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data. Note that you must apply the same scaling to the test set for meaningful results.  There are a lot of different methods for normalization of data, we will use the built-in StandardScaler for standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit only to the training data\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now apply the transformations to the data:\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Now it is time to train our model. SciKit Learn makes this incredibly easy, by using estimator objects. In this case we will import our estimator (the Multi-Layer Perceptron Classifier model) from the neural_network library of SciKit-Learn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-layer Perceptron classifier.\n",
    "\n",
    "hidden_layer_sizes : tuple, length = n_layers - 2, default (100,)\n",
    "    The ith element represents the number of neurons in the ith hidden layer.\n",
    "    \n",
    "max_iter : int, optional, default 200\n",
    "    Maximum number of iterations.\n",
    "    \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create an instance of the model, there are a lot of parameters you can choose to define and customize here, we will only define the hidden_layer_sizes. For this parameter you pass in a tuple consisting of the number of neurons you want at each layer, where the nth entry in the tuple represents the number of neurons in the nth layer of the MLP model. There are many ways to choose these numbers, but for simplicity we will choose 3 layers with the same number of neurons as there are features in our data set along with 500 max iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model has been made we can fit the training data to our model, remember that this data has already been processed and scaled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(13, 13, 13), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the output that shows the default values of the other parameters in the model. I encourage you to play around with them and discover what effects they have on your model!\n",
    "\n",
    "## Predictions and Evaluation\n",
    "\n",
    "Now that we have a model it is time to use it to get predictions! We can do this simply with the predict() method off of our fitted model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use SciKit-Learn's built in metrics such as a classification report and confusion matrix to evaluate how well our model performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  1  0]\n",
      " [ 0 19  1]\n",
      " [ 0  0 12]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.92      0.96        13\n",
      "          2       0.95      0.95      0.95        20\n",
      "          3       0.92      1.00      0.96        12\n",
      "\n",
      "avg / total       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! Looks like we only miss-classified one bottle of wine in our test data! This is pretty good considering how few lines of code we had to write. The downside however to using a Multi-Layer Preceptron model is how difficult it is to interpret the model itself. The weights and biases won't be easily interpretable in relation to which features are important to the model itself.\n",
    "\n",
    "However, if you do want to extract the MLP weights and biases after training your model, you use its public attributes **coefs_** and **intercepts_**. \n",
    "\n",
    "**coefs_** is a list of weight matrices, where weight matrix at index i represents the weights between layer i and layer i+1. \n",
    "\n",
    "**intercepts_** is a list of bias vectors, where the vector at index i represents the bias values added to layer i+1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.n_layers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.classes_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlp.coefs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlp.coefs_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35814229,  0.46506385, -0.6172449 ,  0.53565554, -0.66077248,\n",
       "         0.00527603, -0.2482674 ,  0.52484569, -0.47113281,  0.15190556,\n",
       "        -0.44768786,  0.14590381,  0.03425054],\n",
       "       [-0.4353489 , -0.32118848,  0.19896554,  0.4641289 , -0.12483311,\n",
       "         0.02507317, -0.19270158,  0.11439864,  0.06334025,  0.27253597,\n",
       "         0.2380532 ,  0.41625657,  0.42769699],\n",
       "       [ 0.25947137,  0.02811917, -0.57450845,  0.14369389, -0.20943868,\n",
       "        -0.15006936,  0.21943546,  0.46557889,  0.4860571 ,  0.6114804 ,\n",
       "        -0.04501293, -0.3330587 ,  0.42957144],\n",
       "       [-0.19906937, -0.28728993, -0.13657929, -0.13021902, -0.14801379,\n",
       "         0.41382951,  0.33825494, -0.05192052, -0.11849871, -0.27597534,\n",
       "         0.31791052, -0.24052481, -0.29304648],\n",
       "       [ 0.34426779,  0.04355203, -0.00670418,  0.3348819 ,  0.49337009,\n",
       "        -0.496103  ,  0.40796479, -0.25829924,  0.69661954,  0.08294006,\n",
       "        -0.27773454, -0.15377868, -0.21067064],\n",
       "       [ 0.039212  , -0.22652001, -0.48544959,  0.22770469,  0.35823437,\n",
       "        -0.00476068, -0.04071491,  0.15552911,  0.34357614,  0.04568463,\n",
       "         0.03266211,  0.18202008, -0.14627834],\n",
       "       [ 0.14469165,  0.022523  , -0.02403408,  0.50300629,  0.06143535,\n",
       "         0.09084694,  0.10600547, -0.06639764, -0.10950774, -0.36309051,\n",
       "        -0.0848704 ,  0.16626944, -0.45167796],\n",
       "       [-0.17826618,  0.33099606, -0.23671364, -0.27138161,  0.31486549,\n",
       "         0.34204554,  0.07976496,  0.18742553, -0.21188353, -0.12092551,\n",
       "        -0.19412577,  0.32976069,  0.15633884],\n",
       "       [ 0.27028834, -0.12286555,  0.5652182 , -0.15861428, -0.18423876,\n",
       "        -0.00840344, -0.31611186, -0.49930762,  0.36689337,  0.26491473,\n",
       "         0.26483866,  0.54410255, -0.22699271],\n",
       "       [-0.11003105, -0.16323253, -0.2198804 , -0.2777899 , -0.1187676 ,\n",
       "        -0.47456388, -0.05518909,  0.28918006, -0.25913448,  0.12587193,\n",
       "        -0.56100422, -0.03835118,  0.28293539],\n",
       "       [ 0.30764981,  0.52650481, -0.22260171,  0.06486901, -0.15287989,\n",
       "        -0.05904673, -0.43626811, -0.41793483, -0.10596781, -0.43690067,\n",
       "         0.52233046,  0.31991055, -0.50182376],\n",
       "       [ 0.43201052,  0.30233358, -0.3277617 ,  0.42071993,  0.3426437 ,\n",
       "        -0.35237154, -0.06692197,  0.15848578,  0.29895935, -0.5771733 ,\n",
       "        -0.36270693,  0.02493796, -0.6376117 ],\n",
       "       [ 0.37216528,  0.03339072, -0.40084743,  0.05613039, -0.21433063,\n",
       "        -0.33530801,  0.31805451,  0.60684705, -0.34808468,  0.01443857,\n",
       "         0.12900367,  0.30868639,  0.48271219]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.coefs_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlp.intercepts_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Try playing around with the number of hidden layers and neurons and see how they effect the results!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
