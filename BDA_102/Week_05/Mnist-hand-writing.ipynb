{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "# tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples (numbers from 0-9 with 6000 sample for each), and a test set of 10,000 examples (1000 sample for wach number). It is a subset of a larger set available from MNIST. The digits have been size-normalized and centered in a fixed-size image (28 x 28).\n",
    "It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.\n",
    "\n",
    "mnist=tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mnist=tf.keras.datasets.mnist\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_sys',\n",
       " 'load_data']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting one of the image\n",
    "#,cmap=plt.cm.binary will change the plot to black and white\n",
    "plt.imshow(x_train[0]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# show the tensore\n",
    "print(x_train[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we normalize data to speed up the optimization time\n",
    "# axis=1 means normalize on row\n",
    "x_train=tf.keras.utils.normalize(x_train,axis=1)\n",
    "x_test=tf.keras.utils.normalize(x_test,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- There are two ways to build Keras models: sequential and functional. The sequential API allows you to create models layer-by-layer for most problems. It is limited in that it does not allow you to create models that share layers or have multiple inputs or outputs\n",
    "\n",
    "2- Image is a 2-D vector and in fully connected hidden layer(Dense layer)  we need to flat the inputted data \n",
    "\n",
    "3- Dense layer is a linear operation in which every input is connected to every output by a weight Generally followed by a non-linear activation function.\n",
    "\n",
    "The number of the nodes in each dense layer is a hyper parameter (These are the latent features)\n",
    "The last dense layer should be set to number of the output categories.\n",
    "\n",
    "4- For the more than two output category softmax activation function is a good choice and we can use logistic activation for binary output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a74ee4b53532>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# build the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Sources\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data_format, **kwargs)\u001b[0m\n\u001b[0;32m    586\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_data_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Sources\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36mnormalize_data_format\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m    189\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m   \u001b[0mdata_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'channels_first'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'channels_last'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     raise ValueError('The `data_format` argument must be one of '\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model=tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten((28,28)))\n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common optimizer for at least start is adam\n",
    "\n",
    "For the multi categories output sparse_categorical_crossentropy and for binary output binary_categorical_crossentropy are most commons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 38s 631us/step - loss: 0.2535 - acc: 0.9260\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 37s 611us/step - loss: 0.1005 - acc: 0.9696\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 36s 607us/step - loss: 0.0709 - acc: 0.9779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x10734a908>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we check the model validation for over fitting possibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 243us/step\n",
      "6.3341991928100585 0.6064\n"
     ]
    }
   ],
   "source": [
    "val_loss,val_acc=model.evaluate(x_test,y_test)\n",
    "print(val_loss,val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('test_save')\n",
    "new_model=tf.keras.models.load_model('test_save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction always take a list\n",
    "#shape x_test=(10000, 28, 28)\n",
    "predictions=new_model.predict([x_test])\n",
    "np.shape(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.61712647e-07, 2.55809226e-07, 3.06082402e-05, 1.11375746e-04,\n",
       "       1.38219924e-08, 6.85597297e-06, 3.46534079e-10, 9.99671102e-01,\n",
       "       9.35516709e-07, 1.78059592e-04], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
