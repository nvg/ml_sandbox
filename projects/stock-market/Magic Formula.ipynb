{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joell Greenblatt's Magic Formula\n",
    "\n",
    "Value investing approached based on picking wonderful stocks at bargain price:\n",
    " - Wonderful stock - ROIC - return on invested capital - look at the core competnecy and see how well they are doing it (i.e. exclude excess cash and interest-bearing assets to focus only on the business assets)\n",
    " - Bargain price - is quantified by Earning Yield -> EBIT to Enterprise Value (P/E ratio but capital structure independent)\n",
    "   - ```Earnings Yield = EBIT / Enterprise Value```\n",
    "   - ```ROIC = EBIT / (Net Fixed Assets + Net Working Capital)```\n",
    "   - ```Magic Formula = Rank[Rank(Earnings Yield) + Rank(ROIC)]```\n",
    " - Exclude finance and insurance companies\n",
    " - Accumulate 2-3 positions per month over a 12-month period, then rebalance each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "tickers = [\"AXP\",\"AAPL\",\"BA\",\"CAT\",\"CVX\",\"CSCO\",\"DIS\",\"DOW\", \"XOM\",\n",
    "           \"HD\",\"IBM\",\"INTC\",\"JNJ\",\"KO\",\"MCD\",\"MMM\",\"MRK\",\"MSFT\",\n",
    "           \"NKE\",\"PFE\",\"PG\",\"TRV\",\"UTX\",\"UNH\",\"VZ\",\"V\",\"WMT\",\"WBA\"]\n",
    "\n",
    "#list of tickers whose financial data needs to be extracted\n",
    "financial_dir = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(tickers):\n",
    "    financial_dir = {}\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "        #getting balance sheet data from yahoo finance for the given ticker\n",
    "            temp_dir = {}\n",
    "            url = 'https://in.finance.yahoo.com/quote/'+ticker+'/balance-sheet?p='+ticker\n",
    "            page = requests.get(url)\n",
    "            page_content = page.content\n",
    "            soup = BeautifulSoup(page_content,'html.parser')\n",
    "            tabl = soup.find_all(\"div\", {\"class\" : \"M(0) Mb(10px) Whs(n) BdEnd Bdc($seperatorColor) D(itb)\"})\n",
    "            for t in tabl:\n",
    "                rows = t.find_all(\"div\", {\"class\" : \"rw-expnded\"})\n",
    "                for row in rows:\n",
    "                    temp_dir[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[1]\n",
    "\n",
    "            #getting income statement data from yahoo finance for the given ticker\n",
    "            url = 'https://in.finance.yahoo.com/quote/'+ticker+'/financials?p='+ticker\n",
    "            page = requests.get(url)\n",
    "            page_content = page.content\n",
    "            soup = BeautifulSoup(page_content,'html.parser')\n",
    "            tabl = soup.find_all(\"div\", {\"class\" : \"M(0) Mb(10px) Whs(n) BdEnd Bdc($seperatorColor) D(itb)\"})\n",
    "            for t in tabl:\n",
    "                rows = t.find_all(\"div\", {\"class\" : \"rw-expnded\"})\n",
    "                for row in rows:\n",
    "                    temp_dir[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[1]\n",
    "\n",
    "            #getting cashflow statement data from yahoo finance for the given ticker\n",
    "            url = 'https://in.finance.yahoo.com/quote/'+ticker+'/cash-flow?p='+ticker\n",
    "            page = requests.get(url)\n",
    "            page_content = page.content\n",
    "            soup = BeautifulSoup(page_content,'html.parser')\n",
    "            tabl = soup.find_all(\"div\", {\"class\" : \"M(0) Mb(10px) Whs(n) BdEnd Bdc($seperatorColor) D(itb)\"})\n",
    "            for t in tabl:\n",
    "                rows = t.find_all(\"div\", {\"class\" : \"rw-expnded\"})\n",
    "                for row in rows:\n",
    "                    temp_dir[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[1]\n",
    "\n",
    "            #getting key statistics data from yahoo finance for the given ticker\n",
    "            url = 'https://in.finance.yahoo.com/quote/'+ticker+'/key-statistics?p='+ticker\n",
    "            page = requests.get(url)\n",
    "            page_content = page.content\n",
    "            soup = BeautifulSoup(page_content,'html.parser')\n",
    "            tabl = soup.findAll(\"table\", {\"class\": \"W(100%) Bdcl(c) Mt(10px) \"})\n",
    "            for t in tabl:\n",
    "                rows = t.find_all(\"tr\")\n",
    "                for row in rows:\n",
    "                    if len(row.get_text(separator='|').split(\"|\")[0:2])>0:\n",
    "                        temp_dir[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[-1]    \n",
    "\n",
    "            #combining all extracted information with the corresponding ticker\n",
    "            financial_dir[ticker] = temp_dir\n",
    "        except:\n",
    "            print(\"Problem scraping data for \",ticker)\n",
    "\n",
    "    return financial_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/fin_info.csv'):\n",
    "    financial_dir = scrape(tickers)\n",
    "    #storing information in pandas dataframe\n",
    "    combined_financials = pd.DataFrame(financial_dir)\n",
    "    combined_financials.dropna(how='all',axis=1,inplace=True) #dropping columns with all NaN values\n",
    "    tickers = combined_financials.columns #updating the tickers list based on only those tickers whose values were successfully extracted\n",
    "    for ticker in tickers:\n",
    "        combined_financials = combined_financials[~combined_financials[ticker].str.contains(\"[a-z]\").fillna(False)]\n",
    "    combined_financials.to_csv('data/fin_info.csv')\n",
    "else:\n",
    "    combined_financials = pd.read_csv('data/fin_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't read data for  AXP 'EBITDA'\n",
      "can't read data for  AAPL 'EBITDA'\n",
      "can't read data for  BA 'EBITDA'\n",
      "can't read data for  CAT 'EBITDA'\n",
      "can't read data for  CVX 'EBITDA'\n",
      "can't read data for  CSCO 'EBITDA'\n",
      "can't read data for  DIS 'EBITDA'\n",
      "can't read data for  DOW 'DOW'\n",
      "can't read data for  XOM 'EBITDA'\n",
      "can't read data for  HD 'EBITDA'\n",
      "can't read data for  IBM 'EBITDA'\n",
      "can't read data for  INTC 'EBITDA'\n",
      "can't read data for  JNJ 'EBITDA'\n",
      "can't read data for  KO 'EBITDA'\n",
      "can't read data for  MCD 'EBITDA'\n",
      "can't read data for  MMM 'EBITDA'\n",
      "can't read data for  MRK 'EBITDA'\n",
      "can't read data for  MSFT 'EBITDA'\n",
      "can't read data for  NKE 'EBITDA'\n",
      "can't read data for  PFE 'EBITDA'\n",
      "can't read data for  PG 'EBITDA'\n",
      "can't read data for  TRV 'TRV'\n",
      "can't read data for  UTX 'EBITDA'\n",
      "can't read data for  UNH 'EBITDA'\n",
      "can't read data for  VZ 'EBITDA'\n",
      "can't read data for  V 'V'\n",
      "can't read data for  WMT 'EBITDA'\n",
      "can't read data for  WBA 'WBA'\n"
     ]
    }
   ],
   "source": [
    "# creating dataframe with relevant financial information for each stock using fundamental data\n",
    "stats = [\"EBITDA\",\n",
    "         \"Depreciation & amortization\",\n",
    "         \"Market cap (intra-day)\",\n",
    "         \"Net Income available to common shareholders\",\n",
    "         \"Net cash provided by operating activites\",\n",
    "         \"Capital expenditure\",\n",
    "         \"Total current assets\",\n",
    "         \"Total current liabilities\",\n",
    "         \"Net property, plant and equipment\",\n",
    "         \"Total stockholder equity\",\n",
    "         \"Long-term debt\",\n",
    "         \"Forward annual dividend yield\"] # change as required\n",
    "\n",
    "indx = [\"EBITDA\",\"D&A\",\"MarketCap\",\"NetIncome\",\"CashFlowOps\",\"Capex\",\"CurrAsset\",\n",
    "        \"CurrLiab\",\"PPE\",\"BookValue\",\"TotDebt\",\"DivYield\"]\n",
    "all_stats = {}\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        temp = combined_financials[ticker]\n",
    "        ticker_stats = []\n",
    "        for stat in stats:\n",
    "            ticker_stats.append(temp.loc[stat])\n",
    "        all_stats['{}'.format(ticker)] = ticker_stats\n",
    "    except Exception as e:\n",
    "        print(\"can't read data for \", ticker, e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cleansing of fundamental data imported in dataframe\n",
    "all_stats_df = pd.DataFrame(all_stats,index=indx)\n",
    "all_stats_df[tickers] = all_stats_df[tickers].replace({',': ''}, regex=True)\n",
    "all_stats_df[tickers] = all_stats_df[tickers].replace({'M': 'E+03'}, regex=True)\n",
    "all_stats_df[tickers] = all_stats_df[tickers].replace({'B': 'E+06'}, regex=True)\n",
    "all_stats_df[tickers] = all_stats_df[tickers].replace({'T': 'E+09'}, regex=True)\n",
    "all_stats_df[tickers] = all_stats_df[tickers].replace({'%': 'E-02'}, regex=True)\n",
    "for ticker in all_stats_df.columns:\n",
    "    all_stats_df[ticker] = pd.to_numeric(all_stats_df[ticker].values,errors='coerce')\n",
    "all_stats_df.dropna(axis=1,inplace=True)\n",
    "tickers = all_stats_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculating relevant financial metrics for each stock\n",
    "transpose_df = all_stats_df.transpose()\n",
    "final_stats_df = pd.DataFrame()\n",
    "final_stats_df[\"EBIT\"] = transpose_df[\"EBITDA\"] - transpose_df[\"D&A\"]\n",
    "final_stats_df[\"TEV\"] =  transpose_df[\"MarketCap\"].fillna(0) \\\n",
    "                         +transpose_df[\"TotDebt\"].fillna(0) \\\n",
    "                         -(transpose_df[\"CurrAsset\"].fillna(0)-transpose_df[\"CurrLiab\"].fillna(0))\n",
    "final_stats_df[\"EarningYield\"] =  final_stats_df[\"EBIT\"]/final_stats_df[\"TEV\"]\n",
    "final_stats_df[\"FCFYield\"] = (transpose_df[\"CashFlowOps\"]-transpose_df[\"Capex\"])/transpose_df[\"MarketCap\"]\n",
    "final_stats_df[\"ROC\"]  = (transpose_df[\"EBITDA\"] - transpose_df[\"D&A\"])/(transpose_df[\"PPE\"]+transpose_df[\"CurrAsset\"]-transpose_df[\"CurrLiab\"])\n",
    "final_stats_df[\"BookToMkt\"] = transpose_df[\"BookValue\"]/transpose_df[\"MarketCap\"]\n",
    "final_stats_df[\"DivYield\"] = transpose_df[\"DivYield\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################Output Dataframes##############################\n",
    "\n",
    "# finding value stocks based on Magic Formula\n",
    "final_stats_val_df = final_stats_df.loc[tickers,:]\n",
    "final_stats_val_df[\"CombRank\"] = final_stats_val_df[\"EarningYield\"].rank(ascending=False,na_option='bottom')+final_stats_val_df[\"ROC\"].rank(ascending=False,na_option='bottom')\n",
    "final_stats_val_df[\"MagicFormulaRank\"] = final_stats_val_df[\"CombRank\"].rank(method='first')\n",
    "value_stocks = final_stats_val_df.sort_values(\"MagicFormulaRank\").iloc[:,[2,4,8]]\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"Value stocks based on Greenblatt's Magic Formula\")\n",
    "print(value_stocks)\n",
    "\n",
    "\n",
    "# finding highest dividend yield stocks\n",
    "high_dividend_stocks = final_stats_df.sort_values(\"DivYield\",ascending=False).iloc[:,6]\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"Highest dividend paying stocks\")\n",
    "print(high_dividend_stocks)\n",
    "\n",
    "\n",
    "# # Magic Formula & Dividend yield combined\n",
    "final_stats_df[\"CombRank\"] = final_stats_df[\"EarningYield\"].rank(ascending=False,method='first') \\\n",
    "                              +final_stats_df[\"ROC\"].rank(ascending=False,method='first')  \\\n",
    "                              +final_stats_df[\"DivYield\"].rank(ascending=False,method='first')\n",
    "final_stats_df[\"CombinedRank\"] = final_stats_df[\"CombRank\"].rank(method='first')\n",
    "value_high_div_stocks = final_stats_df.sort_values(\"CombinedRank\").iloc[:,[2,4,6,8]]\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"Magic Formula and Dividend Yield combined\")\n",
    "print(value_high_div_stocks)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
