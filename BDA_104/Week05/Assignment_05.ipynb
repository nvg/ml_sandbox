{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"standard\" imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Upload Titanic dataset \n",
    "\n",
    "df = pd.read_csv('Titanic_original.csv')\n",
    "# y = df['Survived'].map({0: 'no', 1: 'yes'})\n",
    "y = df['Survived']\n",
    "df = df.drop('Survived', axis=1)\n",
    "df = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "df['Male'] = pd.get_dummies(df['Sex'], drop_first=True)\n",
    "df = df.drop('Sex', axis=1)\n",
    "\n",
    "df[['C', 'Q', 'S']] = pd.get_dummies(df['Embarked'])\n",
    "df = df.drop('Embarked', axis = 1)\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=10000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "  n_features_to_select=5, step=1, verbose=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Repeat Assignment 4\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "regrfe = LogisticRegression(solver='lbfgs', max_iter=10000)\n",
    "regrfe.fit(df, y)\n",
    "rfe = RFE(estimator=regrfe, n_features_to_select=5, step=1)\n",
    "rfe.fit(df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Male', 'C', 'Q', 'S'], dtype='object')\n",
      "[ True False  True False False  True  True False  True]\n",
      "[1 4 1 2 5 1 1 3 1]\n",
      "Linear Regression Score\n",
      "0.792368125701459\n",
      "        0                       1\n",
      "0  Pclass   [-0.8348402126833802]\n",
      "1   SibSp   [-0.2755466554907618]\n",
      "2    Male    [-2.592075119000191]\n",
      "3       C   [0.26562131659893856]\n",
      "4       S  [-0.31441483594587694]\n",
      "Confusion Matrix\n",
      "[[152  32]\n",
      " [ 30  81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83       184\n",
      "           1       0.72      0.73      0.72       111\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       295\n",
      "   macro avg       0.78      0.78      0.78       295\n",
      "weighted avg       0.79      0.79      0.79       295\n",
      "\n",
      "Accuracy Score\n",
      "0.7898305084745763\n"
     ]
    }
   ],
   "source": [
    "# now find top 3 features\n",
    "\n",
    "# print summaries for the selection of attributes\n",
    "print(df.columns)\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "\n",
    "# Based on the recursive feature selection ['Pclass', 'SibSb', 'Male', 'C', 'S'] are the significant columns\n",
    "df = df[['Pclass', 'SibSp', 'Male', 'C', 'S']]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.33, random_state=0)\n",
    "reg = LogisticRegression(solver='lbfgs', max_iter=10000)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Compute your modelâ€™s accuracy using accuracy_score\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "print('Linear Regression Score')\n",
    "print(reg.score(df,y))\n",
    "\n",
    "coeff_df = DataFrame(zip(df.columns, np.transpose(reg.coef_)))\n",
    "print(coeff_df)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix')\n",
    "print(cm)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "from sklearn import metrics\n",
    "print('Accuracy Score')\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Use GridSearchCV to fit the logistic regression with a dictionary of values for C .\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gsc = GridSearchCV(\n",
    "        estimator=reg,\n",
    "        param_grid={\n",
    "            'C': [0.1, 0.5, 1, 10, 100, 1000]\n",
    "        },\n",
    "        cv=5, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "grid_result = gsc.fit(X_train, y_train)\n",
    "best_params = grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. See what is the best value for the Hyperparameter, using the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.20302013422818793"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy Score\n",
      "0.7898305084745763\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Original Accuracy Score')\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score at C=0.1 \n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "reg2 = LogisticRegression(solver='lbfgs', C=0.1, max_iter=10000)\n",
    "reg2.fit(X_train, y_train)\n",
    "\n",
    "y_pred2 = reg2.predict(X_test)\n",
    "\n",
    "print('Accuracy Score at C=0.1 ')\n",
    "print(metrics.accuracy_score(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score at C=0.1, L1\n",
      "0.7864406779661017\n",
      "Accuracy Score at C=0.1, L2\n",
      "0.7864406779661017\n"
     ]
    }
   ],
   "source": [
    "# 5. Investigate the difference between L1 and L2 for the outcome. Is there a difference?\n",
    "\n",
    "reg3 = LogisticRegression(solver='liblinear', C=0.1, max_iter=10000, penalty='l1')\n",
    "reg3.fit(X_train, y_train)\n",
    "y_pred3 = reg3.predict(X_test)\n",
    "\n",
    "print('Accuracy Score at C=0.1, L1')\n",
    "print(metrics.accuracy_score(y_test, y_pred3))\n",
    "\n",
    "reg4 = LogisticRegression(solver='liblinear', C=0.1, max_iter=10000, penalty='l2')\n",
    "reg4.fit(X_train, y_train)\n",
    "y_pred4 = reg4.predict(X_test)\n",
    "\n",
    "print('Accuracy Score at C=0.1, L2')\n",
    "print(metrics.accuracy_score(y_test, y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score at C=0.1, L2\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "# normal logistic reg - L2, lbgf - change solver to bilinear, \n",
    "\n",
    "reg5 = LogisticRegression(solver='lbfgs', C=0.1, max_iter=10000, penalty='l2')\n",
    "reg5.fit(X_train, y_train)\n",
    "y_pred5 = reg5.predict(X_test)\n",
    "\n",
    "print('Accuracy Score at C=0.1, L2')\n",
    "print(metrics.accuracy_score(y_test, y_pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Investigate the results of using different cross validation values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score at C=  {'C': 0.5}\n",
      "0.7898305084745763\n",
      "Accuracy Score at C=  {'C': 0.1}\n",
      "0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Sources\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score at C=  {'C': 0.1}\n",
      "0.8\n",
      "Accuracy Score at C=  {'C': 0.1}\n",
      "0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Sources\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in [2, 5, 10, 20]:\n",
    "    gsc = GridSearchCV(\n",
    "            estimator=reg,\n",
    "            param_grid={\n",
    "                'C': [0.1, 0.5, 1, 10, 100, 1000]\n",
    "            },\n",
    "            cv=i, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "    grid_result = gsc.fit(X_train, y_train)\n",
    "    best_params = grid_result.best_params_\n",
    "    \n",
    "    reg = LogisticRegression(solver='lbfgs', C=best_params['C'], max_iter=10000)\n",
    "    reg.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    print('Accuracy Score at C= ', best_params)\n",
    "    print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score at C=  0.1\n",
      "0.8\n",
      "Accuracy Score at C=  0.5\n",
      "0.7898305084745763\n",
      "Accuracy Score at C=  1\n",
      "0.7898305084745763\n",
      "Accuracy Score at C=  10\n",
      "0.7898305084745763\n",
      "Accuracy Score at C=  100\n",
      "0.7898305084745763\n",
      "Accuracy Score at C=  1000\n",
      "0.7898305084745763\n",
      "Accuracy Score at C=  10000\n",
      "0.7898305084745763\n"
     ]
    }
   ],
   "source": [
    "# 7.For the different investigation procedures, plot the accuracy outcome compared \n",
    "# to the different parameters. For example, Accuracy VS. the value of C. \n",
    "\n",
    "c_vs_acc = {}\n",
    "\n",
    "for c in [0.1, 0.5, 1, 10, 100, 1000, 10000]:\n",
    "    reg = LogisticRegression(solver='lbfgs', C=c, max_iter=10000)\n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    print('Accuracy Score at C= ', c)\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "    c_vs_acc[c] = metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "lists = sorted(c_vs_acc.items()) # sorted by key, return a list of tuples\n",
    "x, y = zip(*lists) # unpack a list of pairs into two tuples\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Use Accuracy, Sensitivity, selectivity, and F1-score to assess the final performance of the chosen model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[159  25]\n",
      " [ 34  77]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       184\n",
      "           1       0.75      0.69      0.72       111\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       295\n",
      "   macro avg       0.79      0.78      0.78       295\n",
      "weighted avg       0.80      0.80      0.80       295\n",
      "\n",
      "Accuracy Score\n",
      "0.8\n",
      "f1 Score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7230046948356808"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LogisticRegression(solver='lbfgs', C=0.1, max_iter=10000)\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix')\n",
    "print(cm)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print('Accuracy Score')\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print('f1 Score')\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
